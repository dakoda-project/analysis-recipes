{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767e950f",
   "metadata": {},
   "source": [
    "# ⌛ Reguläre Ausdrücke\n",
    "\n",
    "* Wir  müssen oft beurteilen, ob eine Zeichenkette (String) einem Muster entspricht, eine bestimmte Zeichenfolge oder eine bestimmte Anzahl von Zeichen enthält usw.\n",
    "* Wie andere Programmiersprachen implementiert auch Python  einen allgemeinen Musterabgleichmechanismus, der flexibel und effizient ist: reguläre Ausdrücke.\n",
    "* Wir müssen das Modul für reguläre Ausdrücke importieren.\n",
    "\n",
    "```py\n",
    "import re\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628388f9",
   "metadata": {},
   "source": [
    "## Funktion re.match\n",
    "\n",
    "* Diese Funktion versucht,  einen regulären Ausdruck vom **Anfang** eines Strings her zu matchen.\n",
    "* Die Funktion nimmt ein Muster (pattern) und einen String (string) als Argumente und gibt `None` zurück, falls der String nicht mit dem Muster anfängt, ansonsten gibt sie ein Match-Objekt zurück\n",
    "* `re.match(pattern, string, flags=0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda60f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "words = [ \"Kanzleramt\" , \"Wahlkampf\", \"Bundesseite\", \"Staatsministerin\", \"Bundesinnenministerium\" ,\"Präsidialamt\", \"Ministerpräsidentin\"]\n",
    "for w in words:\n",
    "    print(f\"\\nword {w}\")\n",
    "    bresult= re.match(r'^Bundes', w)\n",
    "    if bresult !=None:\n",
    "        print(f\"{w} beginnt mit 'Bundes' {bresult}\")\n",
    "    else:\n",
    "        print(f\"Suche nach Bundes: {bresult}\")\n",
    "    mresult= re.match(\".*minister.*\", w)\n",
    "    if mresult!=None:\n",
    "        print(f\"{w} enthält 'minister' {mresult}\")\n",
    "    else:\n",
    "        print(f\"Suche nach minister: {mresult}\")\n",
    "    # die nachfolgende Alternative funktionert für Staatsministerin, aber nicht für Ministerpräsidentin\n",
    "    # Q: Was müsste man tun, damit sie auch die Ministerpräsidentin matcht?\n",
    "    if re.match(\".*minister\", w):\n",
    "        print(\"Match für Binnen-minister\")\n",
    "    # die nachfolgende Alternative funktionert NICHT  für Staatsministerin und Ministerpräsidentin\n",
    "    if re.match(\"minister\", w):\n",
    "       print(\"Match für initialen minister\")\n",
    "    else:\n",
    "        print(\"Suche nach initialem minister: Nada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b0e1e",
   "metadata": {},
   "source": [
    "## Funktion re.search\n",
    "\n",
    "* Die Funktion re.search() sucht nach dem **ersten Vorkommen** eines Musters in einem beliebigen Teil eines Strings .\n",
    "* Die Funktion gibt `None` zurück, falls der String nicht mit dem Muster übereinstimmt, ansonsten gibt sie ein Match-Objekt zurück\n",
    "* `re.search(pattern, string, flags=0)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24edca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "words = [ \"Kanzleramt\" , \"Wahlkampf\", \"Bundesseite\", \"Staatsministerin\", \"Bundesinnenministerium\" ,\"Präsidialamt\", \"Ministerpräsidentin\", \"Praesidentin\", \"Praesidium\"]\n",
    "for w in words:\n",
    "    print(f\"{w}\")\n",
    "    # simple Suche nach der Sequenz 'in' egal wo\n",
    "    in_any= re.search(\"in\", w)\n",
    "    if in_any!=None:\n",
    "        print(f\"\\t{w} enthält 'in' {in_any}\")\n",
    "\n",
    "    # Suche nach `in` am Ende des Strings: das Dollarzeichen $ steht für das Ende des Strings\n",
    "    in_end= re.search(\"in$\", w)\n",
    "    if in_end!=None:\n",
    "        print(f\"\\t{w} enthält 'in' am Ende {in_end}\")\n",
    "\n",
    "    # Muster das nach folgenden Formen sucht: präsid/Präsid/praesid oder Praesid \n",
    "    # In eckigen Klammern [] stehen Alternativen, d.h. wir akzeptieren praesid oder Praesid\n",
    "    # In den runden Klammern stehen durch \"|\" getrennt alternative Sequenzen: wir können entweder Präsid oder Praesid haben.\n",
    "    prez = re.search(\"[Pp]r(ä|ae)sid\", w)\n",
    "    if prez!=None:\n",
    "        print(f\"\\t{w} enthält 'Präsid' {prez}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0a684a",
   "metadata": {},
   "source": [
    "## Funktion re.split\n",
    "\n",
    "* Reguläre Ausdrücke können verwendet werden, um Zeichenketten zu teilen.\n",
    "* `re.split(pattern, string, maxsplit=0, flags=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7010a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word=\"Ur-ur-ur-ur-oma\"\n",
    "print(re.split(\"(ur)\", word.lower()))\n",
    "re.split(\"(\\-)\",word.lower())\n",
    "word=\"Ururururoma\"\n",
    "\n",
    "parts = re.split(\"(ur)\", word.lower())\n",
    "print(parts)\n",
    "# Fortgeschritten: Entfernen der leeren Strings in einer sog. list comprehension\n",
    "parts = [part for part in parts if part !='']\n",
    "print(parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce716936",
   "metadata": {},
   "source": [
    "## Funktion re.sub\n",
    "\n",
    "* Ersetzt alle Treffer eines Musters in einem String.\n",
    "* Die Funktion `sub` hat folgende Argumente\n",
    "* `re.sub(pattern, repl, string, count=0, flags=0)`\n",
    "  * `repl` (= replaecment) kann ein String oder eine Funktion sein, die einen String als Argument erwartet und einen ersetzenden String zurückgibt.\n",
    "  * `string` ist der Input-String, der verändert werden soll\n",
    "  * `count` gibt an , wie oft die Ersetzung gemacht werden soll, wenn sie möglich ist. Der Wert 0 hat hier die Sonderinterpretaton, dass alle Instanzen von `pattern` durch `repl` ersetzt werden sollen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"praesidieren\"\n",
    "# ae => ä\n",
    "print(re.sub(\"ae\", \"ä\",word ))\n",
    "# prae => Prä\n",
    "print(re.sub(\"prae\", \"Prä\", word ))\n",
    "word=\"Urururoma\"\n",
    "# wir ersetzen jede Sequenz ur oder Ur durch dieselbe Zeichenfolge und einen Bindestrich\n",
    "# \\\\1 bedeutet das die erste in runden Klammern eingeschlossene Gruppe aus dem Muster wieder verwendet wird. Stichwort: capturing group.\n",
    "print(re.sub(\"([Uu]r)\", \"\\\\1-\", word ))\n",
    "word=\"Bürger:innen\"\n",
    "# Umformatieren des Binnen-i\n",
    "print(re.sub(\":i\", \"I\", word ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa253df",
   "metadata": {},
   "source": [
    "\n",
    "## Funktion re.findall\n",
    "\n",
    "* Sucht alle nicht überlappenden Treffer eines Musters in einem String und gibt sie als Liste zurück.\n",
    "* Man kann mit dem Ergebnis also auch zählen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"SPD\", \"CSU\", \"Die Linke\", \"Bündnis 90/Die Grünen\", \"CDU\", \"ÖDP\", \"Volt\",\"Bundesinnenministerium\" ,\"Präsidialamt\", \"Praeses\"]\n",
    "for w in words:\n",
    "    vowel = re.findall(\"[äöüiouea]\", w.lower())\n",
    "    print(f\"{w} enthält {len(vowel)} Vokale: {vowel}\")\n",
    "    conseq = re.findall(\"[qsdrtzpgkjdmnbcxl]{2,}\", w.lower())\n",
    "    print(f\"{w} enthält {len(conseq)} Konsonantensequenzen: {conseq}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e75ec5",
   "metadata": {},
   "source": [
    "## Funktion re.finditer\n",
    "\n",
    "* Sucht alle nicht überlappenden Treffer eines Musters in einem String und gibt sie sukzessive zurück.\n",
    "* Gibt Details der Treffer zurück.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb787bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = [\"SPD\", \"CSU\", \"Die Linke\", \"Bündnis 90/Die Grünen\", \"CDU\", \"ÖDP\", \"Volt\",\"Bundesinnenministerium\" ,\"Präsidialamt\", \"Praeses\"]\n",
    "for w in words:\n",
    "    for match in re.finditer(\"[qsdrtzpgkjdmnbcxl]{2,}\", w.lower()):\n",
    "        print(f\"In {w} matchen wir {match.group()} von {match.start()} -  {match.end()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b133eb62",
   "metadata": {},
   "source": [
    "## Musterdefinition\n",
    "\n",
    "* Einzelne Zeichen können direkt verwendet werden.\n",
    "* Zeichensequenzen wie 'ober' oder 'erst' können verwendet werden.\n",
    "* Wir können alternative Zeichenfolgen durch \"|\"  verwenden getrennt, um mehrere Alternativen zu akzeptieren.\n",
    "* Das Symbol  '.' steht für ein beliebiges Zeichen.\n",
    "* In eckigen Klammern [] stehen Alternativen.\n",
    "* Das Symbol  '^' in eckigen Klammern zeigt Negation an. [^eiou] bedeutet, dass die genannten Vokale nicht vorkommen dürfen.\n",
    "* Das Symbol  '+' nach einem Zeichen oder einer Zeichensequenz bedeutet, dass es mindestens ein Vorkommen dieser Zeichenfolge oder Zeichen geben muss.\n",
    "* Das Symbol  '*' nach einem Zeichen oder einer Zeichensequenz bedeutet, dass es 0 oder mehr  Vorkommen dieser Zeichenfolge oder Zeichen geben muss.\n",
    "* In geschweiften Klammern kann man angeben, wieviele Vorkommen einer Zeichenfolge oder Zeichen mindestens oder höchstens erlaubt sind.\n",
    "* ^ und $ stehen für den String-Anfang und das String-Ende\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d72be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "word=\"Oberbürgermeisterin\"\n",
    "# alle b's\n",
    "print(re.findall(\"b\",word))\n",
    "\n",
    "# Alle Sequenzen , die mit e beginnen und i enden. greedy (gieriges) matching: wir bilden möglichst lange Sequenzen\n",
    "print(re.findall(\"e.*i\",word))\n",
    "\n",
    "# Alle Sequenzen , die mit e beginnen und i enden. non-greedy matching: wir bilden möglichst kurze Sequenzen\n",
    "print(re.findall(\"e.*?i\",word))\n",
    "\n",
    "# alle Sequenzen , die mit e beginnen und i enden , bei denen dazwischen keine weiteres e kommt.\n",
    "print(re.findall(\"e[^e]*i\",word) )\n",
    "\n",
    "# Alle Sequenzen von mehr als 2 Konsonanten\n",
    "print(re.findall(\"[wrtzpsdfgjklxcvbnm]{2,}\", word))\n",
    "\n",
    "# alle Spannen von 1 oder 2 Vorkommen von \"ur\"\n",
    "word=\"Urururururururoma\"\n",
    "for match in re.finditer(\"(ur){1,2}\",word.lower()):\n",
    "    print(match)\n",
    "# alle Spannen von 1 oder 2 Vorkommen von \"ur\", die nicht am Wortanfang sind (\\B)\n",
    "for match in re.finditer(\"\\B(ur){1,2}\",word.lower()):\n",
    "    print(match)\n",
    "word=\"B52s\"\n",
    "\n",
    "# match all sequences of letter chars\n",
    "print(re.findall(\"[a-zäöüß]+\", word.lower()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c14000-a833-4ce9-981f-d5725c83ca96",
   "metadata": {},
   "source": [
    "## 🫵 Your turn\n",
    "\n",
    "* Auf welche Weisen können Sie  testen, ob ein deutsches Wort mit einem Vokal (Monophthong oder Diphthong) endet?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0872e9-afbd-449b-8def-583b505e7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/end_in_vowel.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf601f-6b72-4e52-a09d-481aabd73cf6",
   "metadata": {},
   "source": [
    "## 🫵 Your turn\n",
    "\n",
    "*  Wir verwenden  die Datei `1091_0000265.txt`, die wir schon beim Wörterzählen oben benutzt hatten.\n",
    "*  Die Aufgabe besteht darin, alle verschiedenen Sequenzen von zwei Wörtern (Bigrammen) zu ermitteln und  zu zählen, wie oft sie im Text vorkommen.\n",
    "*  Wie könnten Sie dazu vorgehen? Können Sie eine der Methoden aus dem `re`-Modul verwenden?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c9d4ae-7b00-468b-885b-f98353b49396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/count_bigrams.py\n",
    "# wir verwenden wieder die Text-Datei aus dem Merlin-Korpus\n",
    "import re\n",
    "path_to_file=\"./data/1091_0000265.txt\"\n",
    "# Die open-Funktion nimmt mehrere Argumente. Das wichtigste ist das erste, der Pfad zur Datei.\n",
    "with open(path_to_file,\"r\", encoding='utf-8') as f:\n",
    "    # mit der Methode readlines lesen wir den Datei-Inhalt in eine Liste von Zeilen.\n",
    "    lines=f.readlines()\n",
    "print(lines)\n",
    "\n",
    "# NB: wir können die obigen Methoden aus re nicht direkt verwenden, weil sie keine überlappenden Treffer zulassen.\n",
    "# Bei einer Sequenz \"Ich mag Eis.\" wolten wir die Bigramme \"Ich mag\" , \"mag Eis\"  und \"Eis .\" finden und nicht  nur \"Ich mag\" und \"Eis .\"\n",
    "\n",
    "records = {}\n",
    "all_tokens = []\n",
    "\n",
    "# Wir erstellen zunächste eine lange Liste von Tokens, in der die Tokens aller Sätze zusammengefügt sind.\n",
    "for z in lines:\n",
    "    # we remove the final newline character\n",
    "    line = z.strip()\n",
    "    # We separate punctuation marks from preceding alphabetic characters (letters)\n",
    "    line = re.sub(\"([a-zA-Zäöü])([\\.\\!\\?,])\",\"\\\\1 \\\\2\",line)\n",
    "    # We split the text of the line into a list of tokens\n",
    "    white_space_tokens = re.split(\"\\s+\",line)\n",
    "    # We join the tokens of all sentences. This means we can get bigrams that cross sentence boundaries!\n",
    "    all_tokens.extend(white_space_tokens)\n",
    "ix=0\n",
    "\n",
    "# Wir ermitteln nun die Bigramme und zählen.\n",
    "#\n",
    "# NB: die Einträge in einer Liste beginnen ab Index 0!\n",
    "#\n",
    "# [\"Ich\", \"mag\" , \"Eis\" , \".\" ] Länge 4\n",
    "# [ 0, 1,2, 3]\n",
    "# \n",
    "# Wir dürfen nicht bis zur letzten Index-Position (3) gehen und dann nach dem Token an Position 3+1 schauen: \n",
    "# es gibt nämlich keine Position 4 und wir würden einen Fehler bekommen.\n",
    "# Der höchste Index ix , den wir besuchen dürfen , ist 2.\n",
    "# Um das sicherzustellen, testen wir, dass  jeder Index, den wir besuchen,  **kleiner** ist als die Tokenanzahl - 1.\n",
    "while ix < len(all_tokens)-1:\n",
    "    bigram = all_tokens[ix]+\"_\"+all_tokens[ix+1]\n",
    "    if bigram not in records:\n",
    "        records[bigram]=0\n",
    "    records[bigram]+=1\n",
    "    ix+=1\n",
    "print(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b7efc-fe3f-4386-959e-92b8d6a38027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir speichern die bigramme zur benutzung in einem späteren notebook\n",
    "import json\n",
    "with open(\"./data/copy_of_bigram_records.json\", \"w\") as f:\n",
    "    json.dump(records, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d2d68-25c2-42f0-8463-7c00f806ed4d",
   "metadata": {},
   "source": [
    "\n",
    "## Alternative Implementierung mit fertigen Bausteinen\n",
    "\n",
    "* Oben haben wir eine handgestrickte Implementation der Bigramm-Ermittlung gesehen.\n",
    "* Soweit wie möglich möchten wir beim Programmieren gerne Code wiederverwenden, den es schon gibt und der gut getestet und optimiert ist.\n",
    "* Unten ist ein Beispiel, wie wir mit einer Kombination aus der `bigrams`-Methode des Natural Language Toolkits (nltk) und einem `Counter` aus dem `collections`-Modul die Bigramm-Frequenzen ermitteln können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb183ac-7ce1-40df-8f6e-95e643fc31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# falls nötig , nltk installieren\n",
    "!pip install  nltk\n",
    "# als erstes nltk importieren\n",
    "import nltk\n",
    "# Download von Daten für das Satzsplitting (muss nur einmal laufen)\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263002dc-f5f9-4c35-9c07-4fdbf5d4842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# wir importieren Funktionen aus dem NLTK-Paket bzw seinen Unterpaketen\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.util import bigrams\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"./data/tagesschau_polen.txt\") as f:\n",
    "    text = f.read()\n",
    "# die Methode zum Sentence splitting braucht eine Angabe zur Sprache!\n",
    "sentences = sent_tokenize(text, language='german')\n",
    "    \n",
    "# Wir besuchen der Reihe nach alle Sätze und teilen sie in Listen von Tokens auf.\n",
    "# Die Tokenliste jedes Satzes fügen wir zu unserer globalen Tokenliste list_of_tokens hinzu. \n",
    "list_of_tokens = []\n",
    "for sentence in sentences:\n",
    "    tokens = word_tokenize(sentence, language='german')\n",
    "    # während die append-Methode von Listen nur ein  Element  hinzufügen kann, fügt die extend-Methode einer Liste alle\n",
    "    # Elemente einer anderen Liste hinzu\n",
    "    list_of_tokens.extend(tokens)\n",
    "\n",
    "c=Counter( bigrams(list_of_tokens))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559c3eaf-627a-4b64-85ef-25923483e8b3",
   "metadata": {},
   "source": [
    "**Your turn**\n",
    "* Wenden Sie den Ansatz mit nltk auf die Datei `./data/1091_0000265.txt` an, die wir  oben mit unserem eigenen Code verarbeitet hatten, an.\n",
    "* Kommen die gleichen Bigramme dabei  heraus?    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ed2f01-db63-4f23-884d-ec5cf844d581",
   "metadata": {},
   "source": [
    "# ✔️ Zusammenfassung reguläre Ausdrücke\n",
    "\n",
    "* Strings bieten nur grundlegende Mustererkennung durch einfache Methoden (z.B. `startswith`, `endswith` )-\n",
    "* Reguläre Ausdrücke (Regex) in Python sind Mustererkennungswerkzeuge, mit denen wir Text anhand flexibler Muster statt anhand exakter Zeichenfolgen durchsuchen können.\n",
    "* Mit Regex können wir Text finden, der einem Muster entspricht, anstatt bestimmte Zeichen zu suchen.\n",
    "* Beispielsweise können wir alle E-Mail-Adressen, Telefonnummern oder Datumsangaben in einem Dokument finden, ohne die genauen Werte zu kennen.\n",
    "\n",
    "* Typische  Anwendungen\n",
    "    * Datenvalidierung – Prüfen, ob Daten korrekt formatiert sind \n",
    "    * Textextraktion – Extraktion bestimmter Informationen aus Dokumenten  oder Metadaten.\n",
    "    * Datenbereinigung – Entfernen von unerwünschten Zeichen oder Strings\n",
    "    * Datenumfomatierung z.B. durch Aufspalten von Strings in Listen von Teilstrings (z.b. Sätzen )\n",
    "\n",
    "```python\n",
    "x=\"Martin ist am 08.03.2001 geboren\"\n",
    "date=re.sub(\"^(.*?)([0-9]{2,2}\\.[0-9]{2,2}\\.[0-9]{4,4})(.*)\", \"\\\\2\",x)\n",
    "print(date)\n",
    "# '08.03.2001'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a11949-c00b-49a7-aa9e-cdcfa041a50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
