{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5230fa9c-a9e6-4866-a45f-b52beaba1d55",
   "metadata": {},
   "source": [
    "# ‚åõ Tabellen\n",
    "\n",
    "* Wir arbeiten h√§ufig mit Tabellen , die z.B. Metadaten enthalten.\n",
    "* Eine g√§ngige Art der Darstellung von Daten ist eine Text-Datei, in der die Spalten durch Kommas oder einen anderen Delimiter getrennt sind.\n",
    "* Wir k√∂nnen auch Excel-Dateien verwenden, um Daten zu speichern und zu laden.\n",
    "* Pandas ist eine g√§ngige  Bibliothek,  um tabellarische Daten zu manipulieren und zu visualisieren.\n",
    "* Wir schauen uns eine Datei zu den Sprecher:innen im Comigs-Korpus an.\n",
    "* Die Datei hat drei Spalten: ID, Proficiencly level und set.\n",
    "  * Es gibt in Comigs zwei Unterkorpora , set 1 und set 2 , die sich u.a. dadurch unterscheiden, dass es beim einen  set zwei manuell erstellte Zielhypothesen gibt und  beim anderen nicht.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb00612-ca8f-4d14-a19b-3f3bbe789316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir importieren zun√§chst zwei Pakete, die wir unten benutzen wollen\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cd1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Wir laden die Datei in einen Pandas-Dataframe mit Hilfe einer Methode der Klasse pandas.\n",
    "# Der Parameter sep=\"\\t\" besagt, dass wir  Tab-getrennte Daten haben. \n",
    "# (Wir verwenden deswegen auch als Dateinamenserweiterung .tsv und nicht .csv .)\n",
    "df = pd.read_csv('./data/comigs_proficiency_levels.tsv',sep=\"\\t\")\n",
    "\n",
    "# Mit head k√∂nnen wir uns die ersten Zeilen des Dataframes anzeigen lassen\n",
    "print(f\"HEAD:\\n {df.head()}\") \n",
    "# Das Gegenst√ºck f√ºr die letzten Zeilen ist tail()\n",
    "\n",
    "print(f\"TAIL:\\n {df.tail()}\") \n",
    "\n",
    "# Ausgabe der ganzen Tabelle\n",
    "print(df)\n",
    "\n",
    "# L√§nge der Tabelle\n",
    "print(f\"Tabelle hat {len(df)} Zeilen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir k√∂nnen uns Information √ºber die Datentypen in den Spalten anzeigen lassen:\n",
    "print(df.info())\n",
    "\n",
    "# Ebenso macht es meist Sinn zu pr√ºfen, ob die Daten vollst√§ndig sind.\n",
    "print(\"Fehlende Werte je Spalte: \\n\")\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir sortieren die Tabelle: zuerst aufsteigend nach set, dann nach Proficiency level, und dann nach ID\n",
    "# inplace=True f√ºhrt dazu, dass die sortierte Tabelle direkt in df gespeichert wird, ohne einen neuen Dataframe zu erzeugen.\n",
    "df.sort_values(by=[\"set\", \"Proficiency level\", \"ID\" ], ascending=True, inplace=True)  \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1c1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wenn wir nur an Set 1 interessiert sind, k√∂nnen wir  einen Unter-Datenframe erzeugen, in dem wir nur die Zeilen f√ºr set 1  behalten \n",
    "# NB: beachten Sie die Syntax, mit der  wir die Zeilen des Dataframes filtern.\n",
    "set1_df = df[ df[\"set\"] == 1 ]\n",
    "print(set1_df)\n",
    "print(len(set1_df))\n",
    "\n",
    "# wir k√∂nnen den neuen Dataframe in eine TSV-Datei speichern - pandas dataframes haben dazu die Methode `to_csv`.\n",
    "set1_df.to_csv(\"set1_df.tsv\",sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03a7c96",
   "metadata": {},
   "source": [
    "## ü´µ Your turn\n",
    "\n",
    "* Erstellen Sie eine Liste mit den IDs der Lerner:innen aus Set2, die das GER-Niveau A2 haben (Spalte 'Proficiency level').\n",
    "* Kommentieren Sie den load-Befehl in der n√§chsten Zelle aus, wenn Sie eine L√∂sung sehen wollen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0fad9-780e-4ba9-8c4f-02cf7ff9506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/find_set2_level_a2_learners.py\n",
    "set2_ids = df[ df[\"set\"] == 2 ][\"ID\"].tolist()\n",
    "a2_ids = df[ df[\"Proficiency level\"] == \"A2\"][\"ID\"].tolist()\n",
    "schnittmenge=set(set2_ids).intersection(set(a2_ids))\n",
    "print(list(schnittmenge))\n",
    "\n",
    "# Kompaktere Alternative, die die Funktionalit√§t von pandas nutzt: \n",
    "# wir bilden einen neuen Dataframe, in dem wir nur die Zeilen f√ºr Set 2 und Proficiency level A2 behalten.\n",
    "set2_a2_df = df[ (df[\"set\"] == 2) & (df[\"Proficiency level\"] == \"A2\") ]\n",
    "print(set2_a2_df[\"ID\"].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d4a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zugriff auf eine einzelne Spalte:\n",
    "print(df[\"Proficiency level\"])\n",
    "\n",
    "# Welche Proficiency levels kommen in der Spalte \"Proficiency level\" vor?\n",
    "print(df[\"Proficiency level\"].unique())\n",
    "# Wie oft kommt jeder der Proficiency levels vor?\n",
    "print(df[\"Proficiency level\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8885a27c",
   "metadata": {},
   "source": [
    "## ü´µ Your turn\n",
    "\n",
    "* \tWie k√∂nnen Sie bestimmen, wie viele Lerner:innen in Set 1 und Set 2 jeweils vorhanden sind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593bca5-6eae-4ee1-90f0-c190d0672fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/count_learners_per_set.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e4ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir wollen schauen , ob die gleichen Proficiency levels in beiden sets vorkommen.\n",
    "\n",
    "set1_proficiency_levels = df[df[\"set\"] == 1][\"Proficiency level\"].unique()\n",
    "set2_proficiency_levels = df[df[\"set\"] == 2][\"Proficiency level\"].unique()\n",
    "\n",
    "print(f\"Set 1 Proficiency Levels: {set1_proficiency_levels}\")\n",
    "print(f\"Set 2 Proficiency Levels: {set2_proficiency_levels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaef938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir m√∂chten uns nun die Anzahl der Lerner:innen pro Proficiency level pro Set anzeigen lassen.\n",
    "# Wir erstellen mit der Funktion crosstab eine Kreuztabelle aus den beiden Variablen.\n",
    "print(pd.crosstab(df[\"Proficiency level\"], df[\"set\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir m√∂chten die Daten in der Tabelle umformatieren und die Info in Proficiency levels in 2 Spalten \"Proficiency Min\" und \"Proficeincy Max\" aufteilen.\n",
    "# Wenn ein einfacher Wert in der Spalte \"Proficiency level\" steht, schreiben wir ihn in die beiden neuen Spalten \"Proficiency Min\" und \"Proficiency Max\" .\n",
    "# Wenn ein Wert mit \"/\" in der Spalte steht (z.B. A2/B1), trennen wir den Eintrag und schreiben den linken Wert in \"Proficiency Min\" und den rechten Wert in \"Proficiency Max\".\n",
    "\n",
    "# Wir k√∂nnen neue Spalten zu einem Datenframe hinzuf√ºgen.\n",
    "\n",
    "df[\"Proficiency Min\"]=\"\"\n",
    "df[\"Proficiency Max\"]=\"\"\n",
    "for ix, row in df.iterrows():\n",
    "\tif \"/\" in row[\"Proficiency level\"]:\n",
    "\t\tdf.loc[ix, \"Proficiency Min\"] = row[\"Proficiency level\"].split(\"/\")[0]\n",
    "\t\tdf.loc[ix, \"Proficiency Max\"] = row[\"Proficiency level\"].split(\"/\")[1]\n",
    "\telse:\n",
    "\t\tdf.loc[ix, \"Proficiency Min\"] = row[\"Proficiency level\"]\n",
    "\t\tdf.loc[ix, \"Proficiency Max\"] = row[\"Proficiency level\"]\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a049c6",
   "metadata": {},
   "source": [
    "## ü´µ Your turn\n",
    "\n",
    "* Ver√§ndern Sie den obigen Code so, dass Sie m√∂glichst die Methoden aus dem Modul `re` verwenden, um die Eintr√§ge in \"Proficiency Min\" und \"Proficiency Max\" zu extrahieren.\n",
    "* (Sie k√∂nnen eine L√∂sung sehen, in dem  Sie den load-Befehl in der n√§chsten Zelle auskommentieren, den Code laden und dann ausf√ºhren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9551e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/use_re_module.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70063b6-cfad-4c92-995f-3ca1abc329d6",
   "metadata": {},
   "source": [
    "* In der Code-Zelle unten k√∂nnen Sie eine noch eine kompaktere Version sehen, um die Info in Proficiency level aufzuteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716164f4-238a-4fb9-85aa-f36c360a1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/apply_example.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71357e2",
   "metadata": {},
   "source": [
    "## ü´µ Your turn\n",
    "\n",
    "* Erstellen Sie neue Kreuztabellen mit den Proficiency levels in \"Proficiency Min\" und \"Proficiency Max\" pro Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709eb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/create_crosstabs.py\n",
    "crosstab_min = pd.crosstab(df[\"Proficiency Min\"], df[\"set\"])\n",
    "crosstab_max = pd.crosstab(df[\"Proficiency Max\"], df[\"set\"])\n",
    "\n",
    "print(crosstab_min)\n",
    "print(crosstab_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6ab90d",
   "metadata": {},
   "source": [
    "## Erstellen von Dataframes aus Listen  und Dictionaries\n",
    "\n",
    "* DataFrames / Tabellen haben eine nat√ºrliche Verwandtschaft zu Listen und Dictionaries.\n",
    "* Wir k√∂nnen die einzelnen Spalten als Listen verstehen.\n",
    "* Wir k√∂nnen Zeilen als Dictionaries verstehen, wobei die Schl√ºssel die Spaltennamen und die Werte die Spaltenwerte in den relevanten Zellen sind.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff878f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In einem anderen Notebook  haben wir Worth√§ufigkeiten f√ºr eine Datei aus dem Merlin-Korpus ermittelt\n",
    "# und in dem Dictionary `freq_records` gespeichert.\n",
    "# Wir laden diese Info hier wieder\n",
    "with open(\"./data/copy_freq_data.json\", \"r\") as f:\n",
    "    freq_records = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "print(freq_records)\n",
    "\n",
    "# Wir erzeugen aus den Schl√ºsseln und Werten zwei parallele Listen.\n",
    "# NB: die keys()-Methode von dictionaries gibt nicht direkt eine Liste zur√ºck.\n",
    "# Wir k√∂nnen den R√ºckgabewert mit list() wieder in eine Liste umwandeln.\n",
    "words = list(freq_records.keys())\n",
    "freqs = list(freq_records.values())\n",
    "# Wir schauen uns einige der Werte in den Listen an.\n",
    "print(words[0:5])\t\n",
    "print(freqs[0:5])\n",
    "# Erstellen eines Dataframes aus parallelen Listen\n",
    "# Beachte: wir m√ºssen am Ende ein dictionary haben, dessen Schl√ºssel die Spaltennamen und dessen Werte die zugeh√∂rigen Listen f√ºr die Werte in den Zeilen  sind.\n",
    "df_words_freqs = pd.DataFrame({\"word\": words, \"frequency\": freqs})\n",
    "print(df_words_freqs.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Wir haben in einem anderen Notebook ein Dictionary namens `records` mit den H√§ufigkeiten von Bigrammen erzeugt.\n",
    "#  Das hatten wir auf Disk gespeihert. Wir laden diese Info hier wieder.\n",
    "\n",
    "with open(\"./data/copy_of_bigram_records.json\", \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "print(records)\n",
    "\n",
    "\n",
    "\n",
    "# Wir wandeln die Information  in eine Liste von Dictionaries um. \n",
    "# Jedes dictionary hat 2 key-value Paare, eines f√ºr das Bigramm und eines f√ºr seine H√§ufigkeit.\n",
    "# Aus der Liste von dictionaries k√∂nnen wir einen DataFrame erzeugen.\n",
    "row_list  =[]\n",
    "for kee,val in records.items():\n",
    "\trow_dict = {\"bigram\": kee, \"frequency\": val}\n",
    "\trow_list.append(row_dict)\n",
    "print(f\"row_list {row_list[0:5]}\")\n",
    "bigram_df = pd.DataFrame(row_list)\n",
    "print(bigram_df.head())\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928fd7ec",
   "metadata": {},
   "source": [
    "## ü´µ Your turn \n",
    "\n",
    "\n",
    "* Oben haben wir ein Dictionary `vowel_frequencies` erstellt.\n",
    "* Wandeln Sie die Werte in einen Dataframe um.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927ea58-049f-4095-a045-5bc5d52eee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zun√§chst laden wir vowel frequencies wieder\n",
    "\n",
    "import json\n",
    "\n",
    "# Load from file\n",
    "with open(\"./data/copy_of_vowel_frequencies.sjon\", \"r\") as f:\n",
    "    vowel_frequencies = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b1e82-6e6a-4ddb-aed8-3f6577a40371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/vowel_frequencies_df.py\n",
    "# convert the dictionary vowel_frequencies to a data frame with columns \"vowel\" and \"frequency\"\n",
    "print(vowel_frequencies)\n",
    "row_list = []\n",
    "for vowel, freq in vowel_frequencies.items():\n",
    "    row_dict = {\"vowel\": vowel, \"frequency\": freq}\n",
    "    row_list.append(row_dict)\n",
    "vowel_df = pd.DataFrame(row_list)\n",
    "print(vowel_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ad7965-a5bf-494a-8812-27147b5e16a7",
   "metadata": {},
   "source": [
    "* üöÄ In der folgenden Zelle sind noch zwei alternative L√∂sungen, die kompakter sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431067ca-a0ca-4d4b-a023-423de87ee336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./snippets/vowel_frequencies_df_compact.py\n",
    "# eine weitere noch kompaktere Option\n",
    "df_vowel_freq = pd.DataFrame.from_records(list(vowel_frequencies.items()),columns=[\"vowel\", \"frequency\"])\n",
    "print(df_vowel_freq)\n",
    "\n",
    "\n",
    "# noch eine  kompakte Option, bei der wir die Vokale als Indizes verwenden statt als WeRte in einer Spalte.\n",
    "df_vowel_freq = pd.DataFrame.from_dict(vowel_frequencies, orient=\"index\", columns=[\"frequency\"])\n",
    "print(df_vowel_freq.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c54fd",
   "metadata": {},
   "source": [
    "# Visualisierung\n",
    "\n",
    "* pandas stellt auch Methoden bereit , um Daten zu visualiseren.\n",
    "* Zum Beispiel k√∂nnen wir aus den oben erstellten Crosstabs  Barplots erstellen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d4996",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosstab_min.plot(kind=\"bar\", stacked=True, rot=0)\n",
    "crosstab_min.plot(kind=\"bar\", stacked=False, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af7909a-1859-4246-a59f-3881fbce5055",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
